{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036055e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SplitNN for the bank marketing dataset\n",
    "\n",
    "- Active_party\n",
    "    - Has model segment 1\n",
    "    - Has first 10 features\n",
    "    - Outsource label to Server for assisting computation\n",
    "- Passive_party\n",
    "    - Has model segment 2\n",
    "    - Has last 10 features\n",
    "- Server\n",
    "    - Has model segment 3\n",
    "    - Has sample labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6094e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from bank_dataset import BankDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cdf8d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len(samples): 7718 Positive labels sum: 3859.0\n",
      "<bank_dataset.BankDataset object at 0x7f5eff2a25d0> 7718\n",
      "example sample data:  tensor([2.3945e-01, 1.0009e-01, 1.0000e+00, 3.3344e-01, 1.0000e+00, 9.9900e-04,\n",
      "        9.9900e-04, 9.9900e-04, 6.6670e-01, 5.0012e-01, 3.6697e-01, 2.9440e-02,\n",
      "        1.0000e+00, 1.6664e-04, 5.0025e-01, 3.3347e-01, 2.6997e-01, 1.9250e-01,\n",
      "        1.5730e-01, 5.1229e-01])\n",
      "example sample label:  tensor(1.)\n",
      "torch.Size([20]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "bank_set = BankDataset('dataset/bank_additional_full_filtered_balanced.csv')\n",
    "print(bank_set, len(bank_set))\n",
    "\n",
    "x0, y0 = bank_set[0]\n",
    "print(\"example sample data: \", x0)\n",
    "print(\"example sample label: \", y0)\n",
    "print(x0.shape, y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfa63cc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_set): 6175\n",
      "len(test_set): 1543\n",
      "len(train_loader): 97\n",
      "len(test_loader): 25\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into train_set and test_set\n",
    "ratio = 0.2\n",
    "test_len = int(len(bank_set) * ratio)\n",
    "total_len = int(len(bank_set))\n",
    "train_len = total_len - test_len\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(bank_set, [train_len, test_len])\n",
    "print(\"len(train_set):\", len(train_set))\n",
    "print(\"len(test_set):\", len(test_set))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "print(\"len(train_loader):\", len(train_loader))\n",
    "print(\"len(test_loader):\", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a97e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import syft as sy\n",
    "from splitnn_dataloader import SplitDataLoader\n",
    "\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "129496a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some workers\n",
    "active_party = sy.VirtualWorker(hook, id=\"active_party\")\n",
    "passive_party = sy.VirtualWorker(hook, id=\"passive_party\")\n",
    "server = sy.VirtualWorker(hook, id= \"server\") \n",
    "\n",
    "data_parties = (active_party, passive_party)\n",
    "model_locations = [active_party, passive_party, server]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e015dc19",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create splitnn train loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cd3dc3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "splitnn_train_loader = SplitDataLoader(data_parties=data_parties, data_loader=train_loader)\n",
    "splitnn_test_loader = SplitDataLoader(data_parties=data_parties, data_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5666c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size= [10, 10]\n",
    "hidden_sizes= {\n",
    "    \"active_party\": [32, 16],\n",
    "    \"passive_party\":[32, 16],\n",
    "    \"server\":[16, 1]\n",
    "}\n",
    "\n",
    "# create model segment for each worker\n",
    "models = {\n",
    "    \"active_party\": nn.Sequential(\n",
    "                nn.Linear(input_size[0], hidden_sizes[\"active_party\"][0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_sizes[\"active_party\"][0], hidden_sizes[\"active_party\"][1]),\n",
    "                nn.ReLU(),\n",
    "    ),\n",
    "    \"passive_party\":  nn.Sequential(\n",
    "                nn.Linear(input_size[1], hidden_sizes[\"passive_party\"][0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_sizes[\"passive_party\"][0], hidden_sizes[\"passive_party\"][1]),\n",
    "                nn.ReLU(),\n",
    "    ),\n",
    "    \"server\": nn.Sequential(\n",
    "                nn.Linear(hidden_sizes[\"server\"][0], hidden_sizes[\"server\"][1]),\n",
    "                # nn.ReLU(),\n",
    "                # nn.Linear(hidden_sizes[\"server\"][1], hidden_sizes[\"server\"][2]),\n",
    "                nn.Sigmoid()\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1986c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizers for each segment and link to their segment\n",
    "optimizers = [\n",
    "    optim.SGD(models[location.id].parameters(), lr=0.05,)\n",
    "    for location in model_locations\n",
    "]\n",
    "\n",
    "# send model segment to each party and server\n",
    "for location in model_locations:\n",
    "    models[location.id].send(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a72c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_pointer, models, data_parties, server):\n",
    "    \n",
    "    # individual party's output upto their respective cut layer\n",
    "    parties_output = {}\n",
    "\n",
    "    # outputs that is moved to server and subjected to concatenate for server input\n",
    "    remote_outputs = []\n",
    "\n",
    "    # iterate over each party and pass their inputs to respective\n",
    "    # model segment and send outputs to server\n",
    "    for party in data_parties:\n",
    "        parties_output[party.id] = models[party.id](data_pointer[party.id])\n",
    "        remote_outputs.append(\n",
    "            parties_output[party.id].copy().move(server)\n",
    "        )\n",
    "\n",
    "    # aggregate outputs from all parties at server's location\n",
    "    server_input = []\n",
    "    for (j, output) in enumerate(remote_outputs):\n",
    "        if j == 0:\n",
    "            server_input = output\n",
    "        else:\n",
    "            server_input = torch.add(server_input, output)\n",
    "\n",
    "    # pass concatenated output from server's model segment\n",
    "    pred = models[\"server\"](server_input)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89463dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, dataloader, dataset_name):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data_ptr, label in dataloader:\n",
    "            output = predict(data_ptr, models, data_parties, server).get()\n",
    "            correct += ( (output > 0.5).squeeze() ).eq(label).sum().item()\n",
    "    \n",
    "    accuracy = 100. * correct / (len(dataloader) * 64)\n",
    "    \n",
    "    print(\"{}: Accuracy {}/{} ({}%)\".format(dataset_name, \n",
    "                                            correct,\n",
    "                                            len(dataloader) * 64,\n",
    "                                            accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "140a70b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_pointer, target, data_parties, models, optimizers, server):\n",
    "    # make grads zero\n",
    "    for opt in optimizers:\n",
    "        opt.zero_grad()\n",
    "\n",
    "    # individual party's output upto their respective cut layer\n",
    "    parties_output = {}\n",
    "\n",
    "    # outputs that is moved to server and subjected to concatenate for server input\n",
    "    remote_outputs = []\n",
    "\n",
    "    # iterate over each party and pass their inputs to respective\n",
    "    # model segment and send outputs to server\n",
    "    for party in data_parties:\n",
    "        parties_output[party.id] = models[party.id](data_pointer[party.id])\n",
    "        remote_outputs.append(\n",
    "            parties_output[party.id].copy().move(server)\n",
    "        )\n",
    "\n",
    "    # concat outputs from all parties at server's location\n",
    "    server_input = []\n",
    "    for (j, output) in enumerate(remote_outputs):\n",
    "        if j == 0:\n",
    "            server_input = output\n",
    "        else:\n",
    "            server_input = torch.add(server_input, output)\n",
    "\n",
    "    # pass concatenated output from server's model segment\n",
    "    pred = models[\"server\"](server_input)\n",
    "\n",
    "    # compute loss\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    loss = criterion(pred, target)\n",
    "\n",
    "    # back-propagate\n",
    "    loss.backward()\n",
    "\n",
    "    # print(\"pred: \", pred)\n",
    "    pred_get = pred.get()\n",
    "    target_get = target.get()\n",
    "    correct = ( (pred_get > 0.5).squeeze() ).eq(target_get).sum().item()\n",
    "    total = pred_get.shape[0]\n",
    "\n",
    "    for i, party in enumerate(data_parties):\n",
    "        grads = remote_outputs[i].grad.copy().move(party)\n",
    "        parties_output[party.id].backward(grads)\n",
    "\n",
    "    # update the weights\n",
    "    for opt in optimizers:\n",
    "        opt.step()\n",
    "\n",
    "    return loss.detach().get(), correct, total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23910f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9c19ca6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py:414: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\n",
      "  response = command_method(*args_, **kwargs_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.672577977180481\n",
      "Train set: Accuracy 4414/6144 (71.84244791666667%)\n",
      "Test set: Accuracy 1115/1536 (72.59114583333333%)\n",
      "Epoch 1 - Training loss: 0.6415541768074036\n",
      "Train set: Accuracy 4494/6144 (73.14453125%)\n",
      "Test set: Accuracy 1141/1536 (74.28385416666667%)\n",
      "Epoch 2 - Training loss: 0.5951734781265259\n",
      "Train set: Accuracy 4467/6144 (72.705078125%)\n",
      "Test set: Accuracy 1132/1536 (73.69791666666667%)\n",
      "Epoch 3 - Training loss: 0.5628591179847717\n",
      "Train set: Accuracy 4445/6144 (72.34700520833333%)\n",
      "Test set: Accuracy 1130/1536 (73.56770833333333%)\n",
      "Epoch 4 - Training loss: 0.550917387008667\n",
      "Train set: Accuracy 4475/6144 (72.83528645833333%)\n",
      "Test set: Accuracy 1133/1536 (73.76302083333333%)\n",
      "Epoch 5 - Training loss: 0.5442378520965576\n",
      "Train set: Accuracy 4510/6144 (73.40494791666667%)\n",
      "Test set: Accuracy 1141/1536 (74.28385416666667%)\n",
      "Epoch 6 - Training loss: 0.5379143953323364\n",
      "Train set: Accuracy 4538/6144 (73.86067708333333%)\n",
      "Test set: Accuracy 1156/1536 (75.26041666666667%)\n",
      "Epoch 7 - Training loss: 0.5310038924217224\n",
      "Train set: Accuracy 4549/6144 (74.03971354166667%)\n",
      "Test set: Accuracy 1153/1536 (75.06510416666667%)\n",
      "Epoch 8 - Training loss: 0.521168053150177\n",
      "Train set: Accuracy 4585/6144 (74.62565104166667%)\n",
      "Test set: Accuracy 1164/1536 (75.78125%)\n",
      "Epoch 9 - Training loss: 0.5112078785896301\n",
      "Train set: Accuracy 4634/6144 (75.42317708333333%)\n",
      "Test set: Accuracy 1176/1536 (76.5625%)\n",
      "Epoch 10 - Training loss: 0.49981072545051575\n",
      "Train set: Accuracy 4663/6144 (75.89518229166667%)\n",
      "Test set: Accuracy 1191/1536 (77.5390625%)\n",
      "Epoch 11 - Training loss: 0.4866753816604614\n",
      "Train set: Accuracy 4725/6144 (76.904296875%)\n",
      "Test set: Accuracy 1198/1536 (77.99479166666667%)\n",
      "Epoch 12 - Training loss: 0.4718274772167206\n",
      "Train set: Accuracy 4781/6144 (77.81575520833333%)\n",
      "Test set: Accuracy 1205/1536 (78.45052083333333%)\n",
      "Epoch 13 - Training loss: 0.45545271039009094\n",
      "Train set: Accuracy 4837/6144 (78.72721354166667%)\n",
      "Test set: Accuracy 1213/1536 (78.97135416666667%)\n",
      "Epoch 14 - Training loss: 0.4383684992790222\n",
      "Train set: Accuracy 4898/6144 (79.72005208333333%)\n",
      "Test set: Accuracy 1230/1536 (80.078125%)\n",
      "Epoch 15 - Training loss: 0.4219883382320404\n",
      "Train set: Accuracy 4970/6144 (80.89192708333333%)\n",
      "Test set: Accuracy 1249/1536 (81.31510416666667%)\n",
      "Epoch 16 - Training loss: 0.4080715775489807\n",
      "Train set: Accuracy 5066/6144 (82.45442708333333%)\n",
      "Test set: Accuracy 1271/1536 (82.74739583333333%)\n",
      "Epoch 17 - Training loss: 0.3981468379497528\n",
      "Train set: Accuracy 5117/6144 (83.28450520833333%)\n",
      "Test set: Accuracy 1286/1536 (83.72395833333333%)\n",
      "Epoch 18 - Training loss: 0.39244312047958374\n",
      "Train set: Accuracy 5152/6144 (83.85416666666667%)\n",
      "Test set: Accuracy 1294/1536 (84.24479166666667%)\n",
      "Epoch 19 - Training loss: 0.3891892433166504\n",
      "Train set: Accuracy 5183/6144 (84.35872395833333%)\n",
      "Test set: Accuracy 1298/1536 (84.50520833333333%)\n",
      "Epoch 20 - Training loss: 0.38665884733200073\n",
      "Train set: Accuracy 5188/6144 (84.44010416666667%)\n",
      "Test set: Accuracy 1300/1536 (84.63541666666667%)\n",
      "Epoch 21 - Training loss: 0.3835507333278656\n",
      "Train set: Accuracy 5210/6144 (84.79817708333333%)\n",
      "Test set: Accuracy 1300/1536 (84.63541666666667%)\n",
      "Epoch 22 - Training loss: 0.38007020950317383\n",
      "Train set: Accuracy 5221/6144 (84.97721354166667%)\n",
      "Test set: Accuracy 1298/1536 (84.50520833333333%)\n",
      "Epoch 23 - Training loss: 0.3772803246974945\n",
      "Train set: Accuracy 5222/6144 (84.99348958333333%)\n",
      "Test set: Accuracy 1303/1536 (84.83072916666667%)\n",
      "Epoch 24 - Training loss: 0.3735700845718384\n",
      "Train set: Accuracy 5216/6144 (84.89583333333333%)\n",
      "Test set: Accuracy 1302/1536 (84.765625%)\n",
      "Epoch 25 - Training loss: 0.3706987500190735\n",
      "Train set: Accuracy 5228/6144 (85.09114583333333%)\n",
      "Test set: Accuracy 1303/1536 (84.83072916666667%)\n",
      "Epoch 26 - Training loss: 0.3690856397151947\n",
      "Train set: Accuracy 5235/6144 (85.205078125%)\n",
      "Test set: Accuracy 1303/1536 (84.83072916666667%)\n",
      "Epoch 27 - Training loss: 0.3670891523361206\n",
      "Train set: Accuracy 5233/6144 (85.17252604166667%)\n",
      "Test set: Accuracy 1302/1536 (84.765625%)\n",
      "Epoch 28 - Training loss: 0.36488276720046997\n",
      "Train set: Accuracy 5237/6144 (85.23763020833333%)\n",
      "Test set: Accuracy 1309/1536 (85.22135416666667%)\n",
      "Epoch 29 - Training loss: 0.3629601001739502\n",
      "Train set: Accuracy 5243/6144 (85.33528645833333%)\n",
      "Test set: Accuracy 1307/1536 (85.09114583333333%)\n",
      "Epoch 30 - Training loss: 0.3608754873275757\n",
      "Train set: Accuracy 5242/6144 (85.31901041666667%)\n",
      "Test set: Accuracy 1305/1536 (84.9609375%)\n",
      "Epoch 31 - Training loss: 0.3592654764652252\n",
      "Train set: Accuracy 5247/6144 (85.400390625%)\n",
      "Test set: Accuracy 1307/1536 (85.09114583333333%)\n",
      "Epoch 32 - Training loss: 0.3571673035621643\n",
      "Train set: Accuracy 5246/6144 (85.38411458333333%)\n",
      "Test set: Accuracy 1311/1536 (85.3515625%)\n",
      "Epoch 33 - Training loss: 0.3562691807746887\n",
      "Train set: Accuracy 5246/6144 (85.38411458333333%)\n",
      "Test set: Accuracy 1310/1536 (85.28645833333333%)\n",
      "Epoch 34 - Training loss: 0.35448911786079407\n",
      "Train set: Accuracy 5246/6144 (85.38411458333333%)\n",
      "Test set: Accuracy 1313/1536 (85.48177083333333%)\n",
      "Epoch 35 - Training loss: 0.353361040353775\n",
      "Train set: Accuracy 5252/6144 (85.48177083333333%)\n",
      "Test set: Accuracy 1315/1536 (85.61197916666667%)\n",
      "Epoch 36 - Training loss: 0.3528920114040375\n",
      "Train set: Accuracy 5248/6144 (85.41666666666667%)\n",
      "Test set: Accuracy 1315/1536 (85.61197916666667%)\n",
      "Epoch 37 - Training loss: 0.3514636754989624\n",
      "Train set: Accuracy 5253/6144 (85.498046875%)\n",
      "Test set: Accuracy 1317/1536 (85.7421875%)\n",
      "Epoch 38 - Training loss: 0.3502422571182251\n",
      "Train set: Accuracy 5251/6144 (85.46549479166667%)\n",
      "Test set: Accuracy 1316/1536 (85.67708333333333%)\n",
      "Epoch 39 - Training loss: 0.34948375821113586\n",
      "Train set: Accuracy 5251/6144 (85.46549479166667%)\n",
      "Test set: Accuracy 1317/1536 (85.7421875%)\n",
      "Epoch 40 - Training loss: 0.348101943731308\n",
      "Train set: Accuracy 5257/6144 (85.56315104166667%)\n",
      "Test set: Accuracy 1320/1536 (85.9375%)\n",
      "Epoch 41 - Training loss: 0.3477500081062317\n",
      "Train set: Accuracy 5259/6144 (85.595703125%)\n",
      "Test set: Accuracy 1321/1536 (86.00260416666667%)\n",
      "Epoch 42 - Training loss: 0.34677863121032715\n",
      "Train set: Accuracy 5259/6144 (85.595703125%)\n",
      "Test set: Accuracy 1320/1536 (85.9375%)\n",
      "Epoch 43 - Training loss: 0.34533751010894775\n",
      "Train set: Accuracy 5262/6144 (85.64453125%)\n",
      "Test set: Accuracy 1316/1536 (85.67708333333333%)\n",
      "Epoch 44 - Training loss: 0.3448151648044586\n",
      "Train set: Accuracy 5262/6144 (85.64453125%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 45 - Training loss: 0.343993604183197\n",
      "Train set: Accuracy 5266/6144 (85.70963541666667%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 46 - Training loss: 0.34301871061325073\n",
      "Train set: Accuracy 5270/6144 (85.77473958333333%)\n",
      "Test set: Accuracy 1318/1536 (85.80729166666667%)\n",
      "Epoch 47 - Training loss: 0.3425123989582062\n",
      "Train set: Accuracy 5272/6144 (85.80729166666667%)\n",
      "Test set: Accuracy 1325/1536 (86.26302083333333%)\n",
      "Epoch 48 - Training loss: 0.34163036942481995\n",
      "Train set: Accuracy 5276/6144 (85.87239583333333%)\n",
      "Test set: Accuracy 1319/1536 (85.87239583333333%)\n",
      "Epoch 49 - Training loss: 0.34136533737182617\n",
      "Train set: Accuracy 5278/6144 (85.90494791666667%)\n",
      "Test set: Accuracy 1320/1536 (85.9375%)\n",
      "Epoch 50 - Training loss: 0.3407459855079651\n",
      "Train set: Accuracy 5281/6144 (85.95377604166667%)\n",
      "Test set: Accuracy 1321/1536 (86.00260416666667%)\n",
      "Epoch 51 - Training loss: 0.3396580219268799\n",
      "Train set: Accuracy 5283/6144 (85.986328125%)\n",
      "Test set: Accuracy 1319/1536 (85.87239583333333%)\n",
      "Epoch 52 - Training loss: 0.3390748202800751\n",
      "Train set: Accuracy 5288/6144 (86.06770833333333%)\n",
      "Test set: Accuracy 1323/1536 (86.1328125%)\n",
      "Epoch 53 - Training loss: 0.33813613653182983\n",
      "Train set: Accuracy 5291/6144 (86.11653645833333%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 54 - Training loss: 0.33758679032325745\n",
      "Train set: Accuracy 5291/6144 (86.11653645833333%)\n",
      "Test set: Accuracy 1321/1536 (86.00260416666667%)\n",
      "Epoch 55 - Training loss: 0.3372129499912262\n",
      "Train set: Accuracy 5294/6144 (86.16536458333333%)\n",
      "Test set: Accuracy 1323/1536 (86.1328125%)\n",
      "Epoch 56 - Training loss: 0.3368776738643646\n",
      "Train set: Accuracy 5295/6144 (86.181640625%)\n",
      "Test set: Accuracy 1321/1536 (86.00260416666667%)\n",
      "Epoch 57 - Training loss: 0.33621636033058167\n",
      "Train set: Accuracy 5295/6144 (86.181640625%)\n",
      "Test set: Accuracy 1321/1536 (86.00260416666667%)\n",
      "Epoch 58 - Training loss: 0.33566033840179443\n",
      "Train set: Accuracy 5297/6144 (86.21419270833333%)\n",
      "Test set: Accuracy 1321/1536 (86.00260416666667%)\n",
      "Epoch 59 - Training loss: 0.33538031578063965\n",
      "Train set: Accuracy 5301/6144 (86.279296875%)\n",
      "Test set: Accuracy 1322/1536 (86.06770833333333%)\n",
      "Epoch 60 - Training loss: 0.33500635623931885\n",
      "Train set: Accuracy 5300/6144 (86.26302083333333%)\n",
      "Test set: Accuracy 1322/1536 (86.06770833333333%)\n",
      "Epoch 61 - Training loss: 0.334249347448349\n",
      "Train set: Accuracy 5299/6144 (86.24674479166667%)\n",
      "Test set: Accuracy 1327/1536 (86.39322916666667%)\n",
      "Epoch 62 - Training loss: 0.3334978222846985\n",
      "Train set: Accuracy 5290/6144 (86.10026041666667%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 63 - Training loss: 0.33335983753204346\n",
      "Train set: Accuracy 5292/6144 (86.1328125%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 64 - Training loss: 0.33310168981552124\n",
      "Train set: Accuracy 5295/6144 (86.181640625%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 65 - Training loss: 0.33263781666755676\n",
      "Train set: Accuracy 5298/6144 (86.23046875%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 66 - Training loss: 0.33185601234436035\n",
      "Train set: Accuracy 5299/6144 (86.24674479166667%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 67 - Training loss: 0.33159494400024414\n",
      "Train set: Accuracy 5302/6144 (86.29557291666667%)\n",
      "Test set: Accuracy 1325/1536 (86.26302083333333%)\n",
      "Epoch 68 - Training loss: 0.33140355348587036\n",
      "Train set: Accuracy 5311/6144 (86.44205729166667%)\n",
      "Test set: Accuracy 1320/1536 (85.9375%)\n",
      "Epoch 69 - Training loss: 0.33113962411880493\n",
      "Train set: Accuracy 5313/6144 (86.474609375%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 70 - Training loss: 0.3305399417877197\n",
      "Train set: Accuracy 5311/6144 (86.44205729166667%)\n",
      "Test set: Accuracy 1321/1536 (86.00260416666667%)\n",
      "Epoch 71 - Training loss: 0.3303745985031128\n",
      "Train set: Accuracy 5312/6144 (86.45833333333333%)\n",
      "Test set: Accuracy 1323/1536 (86.1328125%)\n",
      "Epoch 72 - Training loss: 0.3300233781337738\n",
      "Train set: Accuracy 5312/6144 (86.45833333333333%)\n",
      "Test set: Accuracy 1325/1536 (86.26302083333333%)\n",
      "Epoch 73 - Training loss: 0.3297916352748871\n",
      "Train set: Accuracy 5316/6144 (86.5234375%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 74 - Training loss: 0.32929301261901855\n",
      "Train set: Accuracy 5313/6144 (86.474609375%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 75 - Training loss: 0.3289821445941925\n",
      "Train set: Accuracy 5308/6144 (86.39322916666667%)\n",
      "Test set: Accuracy 1325/1536 (86.26302083333333%)\n",
      "Epoch 76 - Training loss: 0.3285813331604004\n",
      "Train set: Accuracy 5314/6144 (86.49088541666667%)\n",
      "Test set: Accuracy 1326/1536 (86.328125%)\n",
      "Epoch 77 - Training loss: 0.32838404178619385\n",
      "Train set: Accuracy 5311/6144 (86.44205729166667%)\n",
      "Test set: Accuracy 1328/1536 (86.45833333333333%)\n",
      "Epoch 78 - Training loss: 0.3276119828224182\n",
      "Train set: Accuracy 5312/6144 (86.45833333333333%)\n",
      "Test set: Accuracy 1325/1536 (86.26302083333333%)\n",
      "Epoch 79 - Training loss: 0.32765015959739685\n",
      "Train set: Accuracy 5311/6144 (86.44205729166667%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 80 - Training loss: 0.3269850015640259\n",
      "Train set: Accuracy 5317/6144 (86.53971354166667%)\n",
      "Test set: Accuracy 1327/1536 (86.39322916666667%)\n",
      "Epoch 81 - Training loss: 0.32686808705329895\n",
      "Train set: Accuracy 5316/6144 (86.5234375%)\n",
      "Test set: Accuracy 1326/1536 (86.328125%)\n",
      "Epoch 82 - Training loss: 0.32641080021858215\n",
      "Train set: Accuracy 5316/6144 (86.5234375%)\n",
      "Test set: Accuracy 1326/1536 (86.328125%)\n",
      "Epoch 83 - Training loss: 0.32627931237220764\n",
      "Train set: Accuracy 5319/6144 (86.572265625%)\n",
      "Test set: Accuracy 1327/1536 (86.39322916666667%)\n",
      "Epoch 84 - Training loss: 0.32593101263046265\n",
      "Train set: Accuracy 5320/6144 (86.58854166666667%)\n",
      "Test set: Accuracy 1330/1536 (86.58854166666667%)\n",
      "Epoch 85 - Training loss: 0.32588639855384827\n",
      "Train set: Accuracy 5331/6144 (86.767578125%)\n",
      "Test set: Accuracy 1330/1536 (86.58854166666667%)\n",
      "Epoch 86 - Training loss: 0.3254190683364868\n",
      "Train set: Accuracy 5322/6144 (86.62109375%)\n",
      "Test set: Accuracy 1324/1536 (86.19791666666667%)\n",
      "Epoch 87 - Training loss: 0.32505878806114197\n",
      "Train set: Accuracy 5330/6144 (86.75130208333333%)\n",
      "Test set: Accuracy 1330/1536 (86.58854166666667%)\n",
      "Epoch 88 - Training loss: 0.3246724307537079\n",
      "Train set: Accuracy 5329/6144 (86.73502604166667%)\n",
      "Test set: Accuracy 1333/1536 (86.78385416666667%)\n",
      "Epoch 89 - Training loss: 0.32484281063079834\n",
      "Train set: Accuracy 5331/6144 (86.767578125%)\n",
      "Test set: Accuracy 1325/1536 (86.26302083333333%)\n",
      "Epoch 90 - Training loss: 0.32429489493370056\n",
      "Train set: Accuracy 5333/6144 (86.80013020833333%)\n",
      "Test set: Accuracy 1331/1536 (86.65364583333333%)\n",
      "Epoch 91 - Training loss: 0.3238247036933899\n",
      "Train set: Accuracy 5338/6144 (86.88151041666667%)\n",
      "Test set: Accuracy 1323/1536 (86.1328125%)\n",
      "Epoch 92 - Training loss: 0.3233977258205414\n",
      "Train set: Accuracy 5330/6144 (86.75130208333333%)\n",
      "Test set: Accuracy 1323/1536 (86.1328125%)\n",
      "Epoch 93 - Training loss: 0.3231126368045807\n",
      "Train set: Accuracy 5342/6144 (86.94661458333333%)\n",
      "Test set: Accuracy 1329/1536 (86.5234375%)\n",
      "Epoch 94 - Training loss: 0.32306939363479614\n",
      "Train set: Accuracy 5346/6144 (87.01171875%)\n",
      "Test set: Accuracy 1330/1536 (86.58854166666667%)\n",
      "Epoch 95 - Training loss: 0.32281357049942017\n",
      "Train set: Accuracy 5342/6144 (86.94661458333333%)\n",
      "Test set: Accuracy 1333/1536 (86.78385416666667%)\n",
      "Epoch 96 - Training loss: 0.32240477204322815\n",
      "Train set: Accuracy 5346/6144 (87.01171875%)\n",
      "Test set: Accuracy 1331/1536 (86.65364583333333%)\n",
      "Epoch 97 - Training loss: 0.32170599699020386\n",
      "Train set: Accuracy 5345/6144 (86.99544270833333%)\n",
      "Test set: Accuracy 1331/1536 (86.65364583333333%)\n",
      "Epoch 98 - Training loss: 0.32172709703445435\n",
      "Train set: Accuracy 5342/6144 (86.94661458333333%)\n",
      "Test set: Accuracy 1333/1536 (86.78385416666667%)\n",
      "Epoch 99 - Training loss: 0.32175594568252563\n",
      "Train set: Accuracy 5349/6144 (87.060546875%)\n",
      "Test set: Accuracy 1334/1536 (86.84895833333333%)\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    #iterate over each datapoints\n",
    "    for data_ptr, label in splitnn_train_loader:\n",
    "\n",
    "        #send labels to server's location for training\n",
    "        label = label.send(server)\n",
    "\n",
    "        loss, correct, total = train(data_ptr, label, data_parties, models, optimizers, server)\n",
    "        running_loss += loss\n",
    "        train_correct += correct\n",
    "        train_total += total\n",
    "\n",
    "    else:\n",
    "        loss = (running_loss/len(train_loader)).item()\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i, loss))\n",
    "        # print(\"train_correct: \", train_correct)\n",
    "        # print(\"train_total: \", train_total)\n",
    "        # print(\"Epoch {} - Training accuracy: {}\".format(i, train_correct/train_total))\n",
    "        train_accuracy = test(models, splitnn_train_loader, \"Train set\")\n",
    "        test_accuracy = test(models, splitnn_test_loader, \"Test set\")\n",
    "        losses.append(loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c4d2a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Testing Accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 3))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(len(losses)), losses, '-ro')\n",
    "plt.title(\"Losses\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(len(train_accuracies)), train_accuracies, '-ro')\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(len(test_accuracies)), test_accuracies, '-ro')\n",
    "plt.title(\"Testing Accuracy\")\n",
    "plt.savefig(\"bank-splitnn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd3bff-5d92-40fc-a5cc-5cf46b76939c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}